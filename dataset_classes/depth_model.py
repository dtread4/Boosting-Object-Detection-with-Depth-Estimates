# David Treadwell

import numpy as np
from PIL import Image

from abc import ABC, abstractmethod

import cv2

from depth_anything_3.api import DepthAnything3


import os
from contextlib import redirect_stdout, redirect_stderr


class DepthModel:
    """
    Factory class to initialize a depth model
    """
    _available_depth_models = {}

    @classmethod
    def initialize_depth_model(cls, model_name, **kwargs):
        """
        Class method to load the specified model

        Args:
            model_name: The name of the depth model to use

        Raises:
            ValueError: If an invalid depth model is passed in, then raise an error

        Returns:
            The initialized depth model, or None if no depth model is specified
        """
        if model_name is None:
            print("NOT using a depth model (RGB inputs)\n")
            return None

        model_name = model_name.lower()
        if model_name not in cls._available_depth_models:
            raise ValueError(f"Unknown model type: {model_name}! Should be in this set of values:\n{cls._available_depth_models}")
        
        print(f"Using depth (RGB-D inputs) generated by depth model: {model_name}\n")
        return cls._available_depth_models[model_name](**kwargs)
    

def register_model(model_name):
    """
    Decorator to auto-register each depth model class with the DepthModel factory class
    These will be registered above each class

    Args:
        model_name: The name of the model to register
    """
    def decorator(cls):
        DepthModel._available_depth_models[model_name] = cls
        return cls
    return decorator


class _DepthModelBase(ABC):
    """
    Class to automatically manage the user-specified depth model and its calls/returns

    Args:
        ABC: Enforces abstract base class implementation
    """
    def __init__(self, device, model_path=None):
        self.device = device
        self.model_path = model_path
        self.model = self._load_model()

    @abstractmethod
    def _load_model(self, verbose=False):
        """
        Loads the model and places it on the object's device.
        Implementation may vary depending on the model

        Args:
            verbose: Whether to print statements when loading the model. Defaults to False.

        Returns:
            A model object
        """
        pass

    @abstractmethod
    def calculate_depth_map(self, input_image, verbose=False):
        """
        Calculates the depth map for a specified input image

        Args:
            input_image: The image to calculate the depth map for
            verbose: Whether to print statements when running inference on model. Defaults to False.

        Returns:
            A 2D numpy array [h, w] of the estimated depths
        """
        pass

    def _normalize_depth_mask(self, depth_map):
        """_summary_

        Args:
            depth_map: The unnormalized depth map

        Returns:
            The depth map normalized
        """
        min_val = np.min(depth_map)
        max_val = np.max(depth_map)

        # If no unique depths are computed, return an array of 0's
        if min_val == max_val:
            return np.zeros(depth_map.shape).astype(np.float32)
        
        # Convert to float and normalize
        normalized_image = (depth_map - min_val) / (max_val - min_val)
        return normalized_image


@register_model("depth_anything_v3")
class DepthAnythingv3(_DepthModelBase):
    """
    Model class for the Depth Anything 3 model
    https://github.com/ByteDance-Seed/Depth-Anything-3/

    Implementation of the Depth Model base class

    Args:
        DepthModel: The base class this class is an implementation of
    """
    def __init__(self, device, model_path=None, da3_model_name="da3-small"):
        self.da3_model_name = da3_model_name
        super().__init__(device, model_path)

    def _load_model(self, verbose=False):
        """
        Loads the correct Depth Anything 3 model from Hugging Face and places it on the object's device.

        Args:
            verbose: Whether to print statements when loading the model. Defaults to False.

        Returns:
            A model object
        """
        with open(os.devnull, "w") as fnull:
            with redirect_stdout(fnull), redirect_stderr(fnull):
                model = DepthAnything3.from_pretrained(f"depth-anything/{self.da3_model_name}").to(self.device)
        return model
    
    def calculate_depth_map(self, images):
        """
        Calculates the depth map for a single input image and return it in the form [h, w]

        Args:
            images: A list of input images (PIL format) for the model to run inference on

        Returns:
            A depth map in the form [h, w]
        """
        # TODO this model uses relative outputs; may want to try a version that uses absolute ones
        # The process_res parameter will have Depth Anything 3 use the closest available resolution
        # to the original input images shape.
        # The process_res_method will have Depth Anything 3 assume that the resolution being passed in corresponds to
        # the long side of the image.
        # https://github.com/ByteDance-Seed/Depth-Anything-3/blob/main/docs/API.md

        min_size = min(min(img.size) for img in images)
        images_resized = [img.resize((min_size, min_size), Image.Resampling.BILINEAR) for img in images]


        # Using the min size and resizing both to this size because depth anything 3 
        # will take a center crop if the images are different sizes. Using the square of the minimum sizes ensures
        # no information is lost. Since the model is coarse anyway, downsampling inputs -> inference -> upsampling
        # will give the best overall results
        with open(os.devnull, "w") as fnull:
            with redirect_stdout(fnull), redirect_stderr(fnull):
                prediction = self.model.inference(
                    images_resized,
                    process_res=min_size
                )

        # The output depth map is resized to the original image's resolution and normalized to [0, 1]
        depth_maps_resized_normalized = [
            self._normalize_depth_mask(cv2.resize(prediction.depth[i], images[i].size, cv2.INTER_LINEAR)) 
            for i in range(prediction.depth.shape[0])
        ]
        
        return depth_maps_resized_normalized

